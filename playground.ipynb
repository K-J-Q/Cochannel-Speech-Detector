{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read('config.ini')\n",
    "config['augmentations']['pad_trunc_noise_multiplier']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jianquan/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] saved_model/CNNtest_epoch0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jianquan/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ml.machineLearning as ml\n",
    "\n",
    "ml.selectModel()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio\n",
    "import IPython.display as ipd\n",
    "\n",
    "trimmed_audio, b = torchaudio.load(\n",
    "    'E:/asdas.wav')\n",
    "\n",
    "trimmed_audio = trimmed_audio[0][0:1000000]\n",
    "print(trimmed_audio.shape)\n",
    "trimmed_audio = torchaudio.functional.vad(trimmed_audio, b)\n",
    "print(trimmed_audio.shape)\n",
    "ipd.Audio(trimmed_audio, rate=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(16000).reshape(16,1000)\n",
    "torch.split(a, 100, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "# from torchaudio.io import StreamReader\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 8000\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    print(data)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-14.9234, -19.3573, -20.6047,  ..., -19.3020, -23.6502, -10.1572],\n",
       "           [-14.1456, -16.7972, -14.2852,  ..., -13.3883, -12.1930,  -9.1235],\n",
       "           [-15.9348, -13.3864, -10.9996,  ..., -10.9768,  -9.6382,  -9.4230],\n",
       "           ...,\n",
       "           [-26.2044, -34.2283, -24.3407,  ..., -25.6786, -22.9877, -25.1647],\n",
       "           [-25.8723, -24.3353, -22.9113,  ..., -23.2596, -23.7183, -22.9274],\n",
       "           [-25.8911, -23.3617, -20.8828,  ..., -22.8951, -26.4350, -21.9160]]],\n",
       " \n",
       " \n",
       "         [[[ -6.1876, -18.1975, -21.7630,  ..., -16.8953, -19.5669,  -9.2485],\n",
       "           [ -5.8430, -17.2877, -15.3249,  ..., -16.3124, -15.5951,  -9.7948],\n",
       "           [ -5.4486, -12.7837, -10.4563,  ...,  -9.4550, -10.1177,  -9.0305],\n",
       "           ...,\n",
       "           [-19.3467, -16.1593, -12.6604,  ..., -15.9390, -18.8141, -18.9353],\n",
       "           [-18.2641, -16.4448, -12.5543,  ..., -18.5182, -20.6087, -24.4357],\n",
       "           [-16.9033, -15.2658, -16.7470,  ..., -19.6858, -23.7999, -21.2178]]],\n",
       " \n",
       " \n",
       "         [[[ -8.5642, -22.5398, -25.1812,  ..., -21.4405, -29.3369, -13.4633],\n",
       "           [ -8.5869, -21.6213, -16.0539,  ..., -24.7058, -17.2573, -14.2594],\n",
       "           [ -8.1680, -13.7820, -12.7561,  ..., -16.5085, -14.5683, -21.4967],\n",
       "           ...,\n",
       "           [-29.5042, -23.2033, -20.6005,  ..., -22.7967, -23.2953, -21.9681],\n",
       "           [-25.9446, -19.7001, -21.5130,  ..., -22.1093, -23.4915, -20.3895],\n",
       "           [-22.4893, -19.0599, -23.2250,  ..., -21.7521, -21.9537, -19.1757]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-14.3066, -19.3013, -27.1757,  ..., -21.3810, -18.7993, -17.4203],\n",
       "           [-14.1986, -16.7023, -15.6169,  ..., -16.6501, -20.3539, -17.5307],\n",
       "           [-14.7972, -13.3643, -10.2470,  ..., -12.6714, -12.7390, -15.1013],\n",
       "           ...,\n",
       "           [-20.2767, -21.9924, -25.7266,  ..., -21.4150, -24.1667, -24.2179],\n",
       "           [-19.1337, -21.0637, -24.5080,  ..., -23.0089, -21.2915, -26.4757],\n",
       "           [-19.9815, -21.7693, -26.9916,  ..., -24.2593, -20.6500, -24.4484]]],\n",
       " \n",
       " \n",
       "         [[[ -8.5166, -24.4799, -19.3680,  ..., -24.6545, -20.7835, -12.9066],\n",
       "           [ -8.2897, -16.8675, -17.2117,  ..., -17.9446, -17.3282, -12.1439],\n",
       "           [ -8.1872, -15.5203, -15.2421,  ..., -12.3373, -11.6578, -13.2923],\n",
       "           ...,\n",
       "           [-23.7826, -15.8191, -14.1991,  ..., -20.2311, -21.3996, -16.3936],\n",
       "           [-15.9146, -15.2384, -12.1333,  ..., -18.2275, -20.4581, -14.5944],\n",
       "           [-14.0003, -19.7205, -12.5709,  ..., -17.2265, -18.2091, -13.7755]]],\n",
       " \n",
       " \n",
       "         [[[-12.5162, -16.1293, -13.7957,  ..., -17.7912, -14.8769, -10.6411],\n",
       "           [-13.1337, -18.0419, -15.0743,  ..., -16.9532, -16.4406, -10.3969],\n",
       "           [-13.4143, -16.3597, -18.4245,  ..., -18.0579, -16.8026,  -9.8699],\n",
       "           ...,\n",
       "           [-24.2318, -19.5504, -16.9009,  ..., -21.3544, -17.9214, -21.0432],\n",
       "           [-31.0303, -19.6085, -25.2766,  ..., -19.1942, -18.5209, -28.4024],\n",
       "           [-30.0924, -19.5577, -25.7032,  ..., -21.7572, -18.5261, -25.8612]]]]),\n",
       " tensor([0, 1, 2,  ..., 0, 1, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import loader.AudioDataset as Augmentation\n",
    "import torch\n",
    "from loader.AudioDataset import createDataset, collate_batch\n",
    "from torch.utils.data import Dataset\n",
    "import audiomentations\n",
    "import loader.utils as utils\n",
    "\n",
    "env_paths, speech_paths = utils.getAudioPaths('/media/jianquan/Data/Processed Audio/')\n",
    "\n",
    "audio_train_dataset = createDataset(env_paths, speech_paths, transformParams = utils.getTransforms(True))\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    audio_train_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    collate_fn = collate_batch\n",
    ")\n",
    "\n",
    "batch = next(iter(test_dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loader.utils as utils\n",
    "\n",
    "train, val = utils.getAudioPaths('E:/Processed Audio', percent=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873 873\n",
      "98 98\n"
     ]
    }
   ],
   "source": [
    "print(len(train[0]), len(train[1]))\n",
    "print(len(val[0]), len(val[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2] [3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "import torchaudio, torch\n",
    "import loader.AudioDataset as AudioDataset\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = [0,1,2,3,4,5]\n",
    "print(a[:3],a[3:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
