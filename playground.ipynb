{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read('config.ini')\n",
    "config['augmentations']['pad_trunc_noise_multiplier']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1,257, 63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "path = 'E:/Original Audio/New folder/for_release/for_release/OV10/overlap_ratio_10.0_sil0.1_1.0_session2_actual10.0/transcription/meeting_info.txt'\n",
    "\n",
    "# import text as tsv, with header and only first 2 columns\n",
    "timestamps = numpy.genfromtxt(path, delimiter='\\t', dtype=None, encoding=None, names=True, usecols=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ground_truth = np.zeros((timestamps.shape[0]+1, 3))\n",
    "ground_truth[0] = [0, timestamps[0][0], 0] \n",
    "\n",
    "for i , (start_time, end_time) in enumerate(timestamps):\n",
    "    next_start_time = timestamps[i+1][0] if i+1 < len(timestamps) else end_time\n",
    "    if end_time > next_start_time:\n",
    "        ground_truth[i+1] = [next_start_time, end_time, 2]\n",
    "    elif end_time < next_start_time:\n",
    "        ground_truth[i+1] = [end_time, next_start_time, 0]\n",
    "    else:\n",
    "        ground_truth[i+1] = [end_time, next_start_time, 1]\n",
    "\n",
    "# export groundtruth as tsv in the same directory as path\n",
    "np.savetxt('mix.txt', ground_truth, delimiter='\\t', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch = torch.randn([2,1,128,63])\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import glob\n",
    "\n",
    "\n",
    "# glob through all the files in the directory get docx\n",
    "word_paths = glob.glob('C:/Users/Jian Quan/OneDrive/Desktop/Intern/ITP Worklog Reflection/*.docx')\n",
    "\n",
    "for word_path in word_paths:\n",
    "    document = Document(word_path)\n",
    "\n",
    "    # Loop through the tables in the document\n",
    "    for table in document.tables:\n",
    "        # Loop through the rows in the table\n",
    "        for row in table.rows:\n",
    "            # Loop through the cells in the row\n",
    "            for cell in row.cells:\n",
    "            # Print the cell's text if Reflection inside\n",
    "                if 'Reflection*2' in cell.text:\n",
    "                    # replace the text with empty string\n",
    "                    cell.text = ''\n",
    "                    cell.width = 0\n",
    "    \n",
    "    # select last 2 lines\n",
    "    for paragraph in document.paragraphs[-2:]:\n",
    "        # replace the text with empty string\n",
    "        paragraph.text = ''\n",
    "\n",
    "    # Save the document in a folder called cleaned\n",
    "    document.save(f'./cleaned/{os.path.basename(word_path)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio\n",
    "import torch_audiomentations as aug\n",
    "import IPython.display as ipd\n",
    "\n",
    "wav, sr = torchaudio.load('./data/omni mic/real/1speaker_2.wav')\n",
    "\n",
    "wav1 = wav[:, 160000:176000]*100\n",
    "wav2 = wav[:, 176000:192000]\n",
    "\n",
    "batch = torch.stack([wav1, wav2])\n",
    "\n",
    "print(batch)\n",
    "# remove dc\n",
    "batch = batch - batch.mean(dim=2, keepdim=True)\n",
    "\n",
    "apply_augmentation = aug.Compose(\n",
    "    transforms=[\n",
    "        aug.PeakNormalization(p=1),\n",
    "        # aug.AddBackgroundNoise(p=1, background_paths='E:/Processed Audio/backgroundNoise', min_snr_in_db=-3,max_snr_in_db=0)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(batch)\n",
    "augmented_batch = apply_augmentation(batch, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(batch[0][0], rate = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(augmented_batch[0][0], rate = 8000)\n",
    "torchaudio.save('test.wav', augmented_batch[0], 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(batch[1][0], rate = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(augmented_batch[1][0], rate = 8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch, torchaudio\n",
    "import torch_audiomentations as aug\n",
    "from glob import glob\n",
    "\n",
    "testAudios = glob('*.wav')\n",
    "\n",
    "for i, testAudio in enumerate(testAudios):\n",
    "    wav, sr = torchaudio.load(testAudio)\n",
    "    if i == 0:\n",
    "        combinedWAV = wav\n",
    "    else:\n",
    "        combinedWAV = torch.cat((combinedWAV, wav),1)\n",
    "\n",
    "\n",
    "torchaudio.save('combinedWAV.wav',src = combinedWAV, sample_rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "def callback(indata, frames, time, status):\n",
    "    print(np.array(indata))\n",
    "\n",
    "stream = sd.InputStream(callback=callback)\n",
    "stream.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7288e82646d3164eca24130947288f8779d11454649f2c02a5dfc42af7f324c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
